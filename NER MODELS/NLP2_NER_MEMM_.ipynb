{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsZ1D7PaD2dM",
        "outputId": "7e43e536-3001-40b3-ef07-984798ddfb15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train sentences: 59924  | Dev: 8528 | Test: 8262\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def load_ndjson(path):\n",
        "    data = []\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "# Load all splits\n",
        "train_1 = load_ndjson(\"train00.json\")\n",
        "train_2 = load_ndjson(\"train01.json\")\n",
        "train_3 = load_ndjson(\"train02.json\")\n",
        "train_4 = load_ndjson(\"train03.json\")\n",
        "dev_data = load_ndjson(\"valid.json\")\n",
        "test_data = load_ndjson(\"test.json\")\n",
        "\n",
        "# Merge train splits\n",
        "train_data = train_1 + train_2 + train_3 + train_4\n",
        "print(f\"Train sentences: {len(train_data)}  | Dev: {len(dev_data)} | Test: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: quick alignment check\n",
        "def check_alignment(data, name):\n",
        "    bad = sum(1 for e in data if len(e[\"tokens\"]) != len(e[\"tags\"]))\n",
        "    print(f\"{name}: {bad} misaligned sentences\")\n",
        "\n",
        "check_alignment(train_data, \"train\")\n",
        "check_alignment(dev_data,   \"dev\")\n",
        "check_alignment(test_data,  \"test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8VHRvQxUqY5",
        "outputId": "dc60d6be-e079-44f1-a86e-c6f1e7f2c525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 0 misaligned sentences\n",
            "dev: 0 misaligned sentences\n",
            "test: 0 misaligned sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Load Tag Dictionary and Convert Sentences\n"
      ],
      "metadata": {
        "id": "PeSmI6XIS0SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the label dictionary (tag string -> index) and build inverse mapping\n",
        "with open(\"label.json\", encoding=\"utf-8\") as f:\n",
        "    tag2idx = json.load(f)\n",
        "\n",
        "idx2tag = {i: t for t, i in tag2idx.items()}\n",
        "\n",
        "# Convert dataset entries into (word, tag_str) pairs per sentence\n",
        "def to_pairs(data):\n",
        "    sents = []\n",
        "    for e in data:\n",
        "        tokens = e[\"tokens\"]\n",
        "        tags_i = e[\"tags\"]\n",
        "        tags_s = [idx2tag[int(t)] for t in tags_i]\n",
        "        sents.append(list(zip(tokens, tags_s)))\n",
        "    return sents\n",
        "\n",
        "train_sents = to_pairs(train_data)\n",
        "dev_sents   = to_pairs(dev_data)\n",
        "test_sents  = to_pairs(test_data)\n",
        "print(\"Sample sentence:\", train_sents[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSznSPybR_tY",
        "outputId": "3116f38b-fa78-49f1-9384-15c53df719fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Sample sentence: [('John', 'B-PERSON'), ('lives', 'O'), ('in', 'O'), ('New', 'B-GPE'), ('York', 'I-GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Step 3: Feature Extraction Function\n"
      ],
      "metadata": {
        "id": "qD5bduwkS5dM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "UP = set(string.ascii_uppercase)\n",
        "DIG = set(string.digits)\n",
        "\n",
        "def shape(word):\n",
        "    # Xxdd pattern-like shape\n",
        "    s = []\n",
        "    for ch in word:\n",
        "        if ch in UP:\n",
        "            s.append('X')\n",
        "        elif ch in DIG:\n",
        "            s.append('d')\n",
        "        elif ch in string.ascii_lowercase:\n",
        "            s.append('x')\n",
        "        else:\n",
        "            s.append(ch)\n",
        "    return ''.join(s)\n",
        "\n",
        "def extract_features(sent, i, prev_tag):\n",
        "    w = sent[i][0]\n",
        "    w_low = w.lower()\n",
        "    prev_w = sent[i-1][0].lower() if i > 0 else \"<START>\"\n",
        "    next_w = sent[i+1][0].lower() if i < len(sent)-1 else \"<END>\"\n",
        "\n",
        "    feats = {\n",
        "        \"bias\": 1.0,\n",
        "        \"w\": w_low,\n",
        "        \"pw\": prev_w,\n",
        "        \"nw\": next_w,\n",
        "        \"prev_tag\": prev_tag,\n",
        "        \"is_title\": w.istitle(),\n",
        "        \"is_upper\": w.isupper(),\n",
        "        \"is_lower\": w.islower(),\n",
        "        \"has_digit\": any(ch.isdigit() for ch in w),\n",
        "        \"is_punct\": all(ch in string.punctuation for ch in w),\n",
        "        \"shape\": shape(w),\n",
        "        \"pref1\": w_low[:1],\n",
        "        \"pref2\": w_low[:2],\n",
        "        \"pref3\": w_low[:3],\n",
        "        \"suf1\": w_low[-1:],\n",
        "        \"suf2\": w_low[-2:],\n",
        "        \"suf3\": w_low[-3:],\n",
        "    }\n",
        "    return feats"
      ],
      "metadata": {
        "id": "CBBE1r58S1Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preparing the training data"
      ],
      "metadata": {
        "id": "vysOxujYXaxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_feats = []\n",
        "y_train_labels = []\n",
        "\n",
        "for sent in train_sents:\n",
        "    prev_tag = \"O\"\n",
        "    for i in range(len(sent)):\n",
        "        feats = extract_features(sent, i, prev_tag)\n",
        "        tag = sent[i][1]\n",
        "        X_train_feats.append(feats)\n",
        "        y_train_labels.append(tag)\n",
        "        prev_tag = tag\n",
        "\n",
        "print(\"✅ Sample features:\", X_train_feats[0])\n",
        "print(\"✅ Sample label:\", y_train_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAKi3ZgiS85K",
        "outputId": "1599a6bd-bfe8-41c6-c121-34fd2b336d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Sample features: {'bias': 1.0, 'w': 'john', 'pw': '<START>', 'nw': 'lives', 'prev_tag': 'O', 'is_title': True, 'is_upper': False, 'is_lower': False, 'has_digit': False, 'is_punct': False, 'shape': 'Xxxx', 'pref1': 'j', 'pref2': 'jo', 'pref3': 'joh', 'suf1': 'n', 'suf2': 'hn', 'suf3': 'ohn'}\n",
            "✅ Sample label: B-PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Train the MEMM (Logistic Regression"
      ],
      "metadata": {
        "id": "iU2NbrCqXTMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "memm = Pipeline([\n",
        "    (\"vec\", DictVectorizer(sparse=True)),\n",
        "    (\"clf\", LogisticRegression(max_iter=300, n_jobs=-1))\n",
        "])\n",
        "\n",
        "memm.fit(X_train_feats, y_train_labels)\n",
        "print(\"✅ MEMM training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R3cn3EjS_3Y",
        "outputId": "016b9280-4de2-4eb5-f349-d9891a61a765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MEMM training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Tags for a Sentence\n"
      ],
      "metadata": {
        "id": "csi0jUfdYROj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def memm_predict(sent):\n",
        "    tags = []\n",
        "    prev_tag = \"O\"\n",
        "    for i in range(len(sent)):\n",
        "        feats = extract_features(sent, i, prev_tag)\n",
        "        pred = memm.predict([feats])[0]\n",
        "        tags.append(pred)\n",
        "        prev_tag = pred\n",
        "    return tags"
      ],
      "metadata": {
        "id": "uljWkow-TCvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evalute on the validation set\n"
      ],
      "metadata": {
        "id": "LacES_x0YcY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for sent in dev_sents:\n",
        "    true_tags = [t for _, t in sent]\n",
        "    pred_tags = memm_predict(sent)\n",
        "    y_true.extend(true_tags)\n",
        "    y_pred.extend(pred_tags)\n",
        "\n",
        "print(\"✅ valid set evaluation:\")\n",
        "print(classification_report(y_true, y_pred, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8LoeA18YSa7",
        "outputId": "174681dc-d272-446a-fe82-1d645380e05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ valid set evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "   B-CARDINAL      0.000     0.000     0.000       937\n",
            "       B-DATE      0.000     0.000     0.000      1507\n",
            "      B-EVENT      0.000     0.000     0.000       143\n",
            "        B-FAC      0.000     0.000     0.000       115\n",
            "        B-GPE      0.207     0.025     0.045      2268\n",
            "   B-LANGUAGE      0.000     0.000     0.000        33\n",
            "        B-LAW      0.000     0.000     0.000        40\n",
            "        B-LOC      0.000     0.000     0.000       204\n",
            "      B-MONEY      0.000     0.000     0.000       271\n",
            "       B-NORP      0.000     0.000     0.000       847\n",
            "    B-ORDINAL      0.000     0.000     0.000       232\n",
            "        B-ORG      0.444     0.002     0.005      1740\n",
            "    B-PERCENT      0.000     0.000     0.000       177\n",
            "     B-PERSON      0.108     0.303     0.160      2020\n",
            "    B-PRODUCT      0.000     0.000     0.000        72\n",
            "   B-QUANTITY      0.000     0.000     0.000       100\n",
            "       B-TIME      0.000     0.000     0.000       214\n",
            "B-WORK_OF_ART      0.000     0.000     0.000       142\n",
            "   I-CARDINAL      0.000     0.000     0.000       290\n",
            "       I-DATE      0.000     0.000     0.000      1809\n",
            "      I-EVENT      0.000     0.000     0.000       272\n",
            "        I-FAC      0.000     0.000     0.000       203\n",
            "        I-GPE      0.750     0.076     0.137       555\n",
            "        I-LAW      0.000     0.000     0.000        84\n",
            "        I-LOC      0.000     0.000     0.000       188\n",
            "      I-MONEY      0.000     0.000     0.000       587\n",
            "       I-NORP      0.000     0.000     0.000        44\n",
            "    I-ORDINAL      0.000     0.000     0.000         4\n",
            "        I-ORG      0.000     0.000     0.000      2336\n",
            "    I-PERCENT      0.000     0.000     0.000       258\n",
            "     I-PERSON      0.000     0.000     0.000      1395\n",
            "    I-PRODUCT      0.000     0.000     0.000       129\n",
            "   I-QUANTITY      0.000     0.000     0.000       209\n",
            "       I-TIME      0.000     0.000     0.000       260\n",
            "I-WORK_OF_ART      0.000     0.000     0.000       334\n",
            "            O      0.874     0.970     0.920    127699\n",
            "\n",
            "     accuracy                          0.844    147718\n",
            "    macro avg      0.066     0.038     0.035    147718\n",
            " weighted avg      0.769     0.844     0.799    147718\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# find the best prameter for the model"
      ],
      "metadata": {
        "id": "ssN2Cv6uZ4Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"vec\", DictVectorizer(sparse=True)),\n",
        "    (\"clf\", LogisticRegression(max_iter=300, solver=\"liblinear\"))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    \"clf__C\": [0.1, 0.5, 1.0, 2.0, 5.0],\n",
        "    \"clf__penalty\": [\"l2\"],\n",
        "    \"clf__class_weight\": [None, \"balanced\"]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=3, verbose=1, n_jobs=-1)\n",
        "grid.fit(X_train_feats, y_train_labels)\n",
        "\n",
        "print(\"✅ Best parameters:\", grid.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6XvvVrcaCID",
        "outputId": "b324460c-f931-4727-c1b8-5de541421d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "✅ Best parameters: {'clf__C': 0.1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_dev_feats = []\n",
        "y_dev_labels = []\n",
        "\n",
        "for sent in dev_sents:\n",
        "    prev_tag = \"O\"\n",
        "    for i in range(len(sent)):\n",
        "        feats = extract_features(sent, i, prev_tag)\n",
        "        tag = sent[i][1]\n",
        "        X_dev_feats.append(feats)\n",
        "        y_dev_labels.append(tag)\n",
        "        prev_tag = tag"
      ],
      "metadata": {
        "id": "q5kFM0jpYkcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# we prepared the valid set and retrain the new model with new parameter on train and valid"
      ],
      "metadata": {
        "id": "vxekaoyZbB2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_all_feats = X_train_feats + X_dev_feats\n",
        "y_all_labels = y_train_labels + y_dev_labels\n",
        "\n",
        "memm.fit(X_all_feats, y_all_labels)\n",
        "print(\" Retrained MEMM on train + valid.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQmm0bqbaGHf",
        "outputId": "93c861d9-12f1-4918-966c-c2b090e87d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Retrained MEMM on train + valid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def memm_predict(sent, model):\n",
        "    tags = []\n",
        "    prev_tag = \"O\"\n",
        "    for i in range(len(sent)):\n",
        "        feats = extract_features(sent, i, prev_tag)\n",
        "        pred = model.predict([feats])[0]\n",
        "        tags.append(pred)\n",
        "        prev_tag = pred\n",
        "    return tags\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for sent in test_sents:\n",
        "    true_tags = [t for _, t in sent]\n",
        "    pred_tags = memm_predict(sent, memm)\n",
        "    y_true.extend(true_tags)\n",
        "    y_pred.extend(pred_tags)\n",
        "\n",
        "print(\"Final test evaluation:\")\n",
        "print(classification_report(y_true, y_pred, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oJlMs9ua4Xa",
        "outputId": "c5e1f3e6-4e12-47b5-d9b5-28bada59a5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final test evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "   B-CARDINAL      0.593     0.686     0.636       935\n",
            "       B-DATE      0.710     0.679     0.694      1602\n",
            "      B-EVENT      0.222     0.032     0.056        63\n",
            "        B-FAC      0.667     0.059     0.109       135\n",
            "        B-GPE      0.786     0.861     0.822      2240\n",
            "   B-LANGUAGE      0.625     0.227     0.333        22\n",
            "        B-LAW      0.667     0.050     0.093        40\n",
            "        B-LOC      0.559     0.318     0.406       179\n",
            "      B-MONEY      0.623     0.543     0.580       313\n",
            "       B-NORP      0.740     0.835     0.784       841\n",
            "    B-ORDINAL      0.574     0.815     0.674       195\n",
            "        B-ORG      0.582     0.456     0.512      1795\n",
            "    B-PERCENT      0.800     0.711     0.753       349\n",
            "     B-PERSON      0.707     0.718     0.713      1988\n",
            "    B-PRODUCT      0.583     0.184     0.280        76\n",
            "   B-QUANTITY      0.320     0.152     0.206       105\n",
            "       B-TIME      0.661     0.340     0.449       212\n",
            "B-WORK_OF_ART      0.576     0.114     0.191       166\n",
            "   I-CARDINAL      0.384     0.329     0.354       331\n",
            "       I-DATE      0.750     0.479     0.585      2011\n",
            "      I-EVENT      0.667     0.015     0.030       130\n",
            "        I-FAC      0.550     0.052     0.094       213\n",
            "        I-GPE      0.508     0.689     0.585       628\n",
            "        I-LAW      1.000     0.010     0.019       105\n",
            "        I-LOC      0.476     0.167     0.247       180\n",
            "      I-MONEY      0.825     0.649     0.726       683\n",
            "       I-NORP      0.854     0.438     0.579       160\n",
            "    I-ORDINAL      0.000     0.000     0.000         4\n",
            "        I-ORG      0.683     0.387     0.494      2406\n",
            "    I-PERCENT      0.917     0.658     0.766       523\n",
            "     I-PERSON      0.724     0.745     0.734      1412\n",
            "    I-PRODUCT      0.000     0.000     0.000        69\n",
            "   I-QUANTITY      0.485     0.160     0.241       206\n",
            "       I-TIME      0.693     0.204     0.315       255\n",
            "I-WORK_OF_ART      0.433     0.039     0.071       337\n",
            "            O      0.965     0.993     0.979    131814\n",
            "\n",
            "     accuracy                          0.935    152723\n",
            "    macro avg      0.609     0.383     0.420    152723\n",
            " weighted avg      0.927     0.935     0.927    152723\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RhbHvn7PbQIJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}