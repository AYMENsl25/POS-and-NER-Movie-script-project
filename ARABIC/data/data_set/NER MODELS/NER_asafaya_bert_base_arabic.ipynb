{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP4ncencF3E2w66ERRh+VxW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdqgDolfuxA1","executionInfo":{"status":"ok","timestamp":1763937274775,"user_tz":-180,"elapsed":12598,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}},"outputId":"4650cefd-fd60-4b56-a7a1-59b2ea0ca90b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.12/dist-packages (1.2.2)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"]}],"source":["!pip install -U datasets accelerate seqeval transformers\n"]},{"cell_type":"code","source":["from datasets import load_dataset\n","import torch\n","from torch.utils.data import DataLoader\n","import numpy as np\n","from seqeval.metrics import f1_score, classification_report\n","\n","dataset = load_dataset(\"asas-ai/ANERCorp\")\n","dataset\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4g5pP5iu2MU","executionInfo":{"status":"ok","timestamp":1763937275919,"user_tz":-180,"elapsed":1137,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}},"outputId":"f264fc41-2517-4f7e-de19-fb68c94dc881"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['word', 'tag'],\n","        num_rows: 125102\n","    })\n","    test: Dataset({\n","        features: ['word', 'tag'],\n","        num_rows: 25008\n","    })\n","})"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["print(dataset[\"train\"][0])\n","print(dataset[\"train\"][1])\n","print(dataset[\"train\"][2])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rmFm_Jd7vAR_","executionInfo":{"status":"ok","timestamp":1763937275932,"user_tz":-180,"elapsed":8,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}},"outputId":"4ddb474e-ff3c-455e-a210-b2ddba479781"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["{'word': 'فرانكفورت', 'tag': 'B-LOC'}\n","{'word': '(د', 'tag': 'O'}\n","{'word': 'ب', 'tag': 'O'}\n"]}]},{"cell_type":"code","source":["SENTENCE_ENDINGS = {\".\", \"؟\", \"!\", \"؛\"}\n","\n","def build_sentences(ds_split):\n","    sentences = []\n","    labels = []\n","\n","    curr_tokens = []\n","    curr_tags = []\n","\n","    for row in ds_split:\n","        w = row[\"word\"]\n","        t = row[\"tag\"]\n","\n","        if w is None or w.strip() == \"\":\n","            continue\n","\n","        curr_tokens.append(w)\n","        curr_tags.append(t)\n","\n","        if w in SENTENCE_ENDINGS:\n","            sentences.append(curr_tokens)\n","            labels.append(curr_tags)\n","            curr_tokens = []\n","            curr_tags = []\n","\n","    if curr_tokens:\n","        sentences.append(curr_tokens)\n","        labels.append(curr_tags)\n","\n","    return sentences, labels\n","\n","train_texts, train_labels = build_sentences(dataset[\"train\"])\n","test_texts, test_labels = build_sentences(dataset[\"test\"])\n","\n","len(train_texts), len(test_texts)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gljXytCFvGqC","executionInfo":{"status":"ok","timestamp":1763937285526,"user_tz":-180,"elapsed":9591,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}},"outputId":"3032984e-cfa6-4eb8-af32-d6c2c230adcb"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4279, 976)"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["all_tags = set()\n","\n","for seq in train_labels + test_labels:\n","    for t in seq:\n","        all_tags.add(t)\n","\n","label_list = sorted(list(all_tags))\n","label2id = {l:i for i,l in enumerate(label_list)}\n","id2label = {i:l for l,i in label2id.items()}\n","\n","label_list, label2id\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q9FsbOrfvJdb","executionInfo":{"status":"ok","timestamp":1763937285559,"user_tz":-180,"elapsed":29,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}},"outputId":"cee2fbd0-a211-482d-ad21-f2a40763eb72"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['B-LOC',\n","  'B-MISC',\n","  'B-ORG',\n","  'B-PERS',\n","  'I-LOC',\n","  'I-MISC',\n","  'I-ORG',\n","  'I-PERS',\n","  'O'],\n"," {'B-LOC': 0,\n","  'B-MISC': 1,\n","  'B-ORG': 2,\n","  'B-PERS': 3,\n","  'I-LOC': 4,\n","  'I-MISC': 5,\n","  'I-ORG': 6,\n","  'I-PERS': 7,\n","  'O': 8})"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForTokenClassification\n","\n","model_name = \"asafaya/bert-base-arabic\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_name,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_mwTbKfvL_e","executionInfo":{"status":"ok","timestamp":1763937286177,"user_tz":-180,"elapsed":616,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}},"outputId":"13bda084-17c9-4421-e2ff-739d3d3b1560"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at asafaya/bert-base-arabic and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def encode_examples(texts, tags):\n","    tokenized_inputs = tokenizer(\n","        texts,\n","        is_split_into_words=True,\n","        truncation=True,\n","        padding=True,\n","        max_length=128\n","    )\n","\n","    all_labels = []\n","\n","    for i, label_seq in enumerate(tags):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        previous_word_idx = None\n","        label_ids = []\n","\n","        for word_idx in word_ids:\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:\n","                label_ids.append(label2id[label_seq[word_idx]])\n","            else:\n","                original_label = label_seq[word_idx]\n","                if original_label.startswith(\"B-\"):\n","                    new_label = \"I-\" + original_label[2:]\n","                else:\n","                    new_label = original_label\n","                label_ids.append(label2id[new_label])\n","            previous_word_idx = word_idx\n","\n","        all_labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = all_labels\n","    return tokenized_inputs\n","\n","train_encodings = encode_examples(train_texts, train_labels)\n","test_encodings  = encode_examples(test_texts, test_labels)\n"],"metadata":{"id":"7QKGKEGYvNrP","executionInfo":{"status":"ok","timestamp":1763937288295,"user_tz":-180,"elapsed":2114,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset\n","\n","train_dataset = Dataset.from_dict(train_encodings)\n","eval_dataset  = Dataset.from_dict(test_encodings)\n","\n","train_dataset.set_format(type=\"torch\")\n","eval_dataset.set_format(type=\"torch\")\n"],"metadata":{"id":"OA5o6fnVvQSr","executionInfo":{"status":"ok","timestamp":1763937289018,"user_tz":-180,"elapsed":718,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","eval_loader  = DataLoader(eval_dataset,  batch_size=8, shuffle=False)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n"],"metadata":{"id":"HkiGxejZvS8W","executionInfo":{"status":"ok","timestamp":1763937289645,"user_tz":-180,"elapsed":623,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, data_loader, label_list):\n","    model.eval()\n","    all_true = []\n","    all_pred = []\n","\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            outputs = model(**batch)\n","            logits = outputs.logits\n","            preds  = torch.argmax(logits, -1)\n","            labels = batch[\"labels\"]\n","\n","            preds  = preds.cpu().numpy()\n","            labels = labels.cpu().numpy()\n","\n","            for p_seq, l_seq in zip(preds, labels):\n","                curr_true, curr_pred = [], []\n","                for p_i, l_i in zip(p_seq, l_seq):\n","                    if l_i == -100:\n","                        continue\n","                    curr_true.append(label_list[l_i])\n","                    curr_pred.append(label_list[p_i])\n","                all_true.append(curr_true)\n","                all_pred.append(curr_pred)\n","\n","    print(\"F1:\", f1_score(all_true, all_pred))\n","    print(classification_report(all_true, all_pred))\n"],"metadata":{"id":"6p2f7lZkvXtE","executionInfo":{"status":"ok","timestamp":1763937289652,"user_tz":-180,"elapsed":3,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["num_epochs = 3\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_loader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","\n","        outputs = model(**batch)\n","        loss = outputs.loss\n","        loss.backward()\n","\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        total_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f}\")\n","    print(\"Validation:\")\n","    evaluate_model(model, eval_loader, label_list)\n","    print(\"-\" * 60)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THXe9QgTvZU1","executionInfo":{"status":"ok","timestamp":1763937610731,"user_tz":-180,"elapsed":321076,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}},"outputId":"ba3e9bb3-947a-4132-962f-12791a3ef610"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss: 0.1431\n","Validation:\n","F1: 0.7554300608166812\n","              precision    recall  f1-score   support\n","\n","         LOC       0.81      0.90      0.85       675\n","        MISC       0.60      0.46      0.52       243\n","         ORG       0.64      0.63      0.64       455\n","        PERS       0.78      0.81      0.79       905\n","\n","   micro avg       0.75      0.76      0.76      2278\n","   macro avg       0.71      0.70      0.70      2278\n","weighted avg       0.74      0.76      0.75      2278\n","\n","------------------------------------------------------------\n","Epoch 2 - Loss: 0.0487\n","Validation:\n","F1: 0.7342851054762412\n","              precision    recall  f1-score   support\n","\n","         LOC       0.82      0.91      0.86       675\n","        MISC       0.54      0.61      0.57       243\n","         ORG       0.58      0.72      0.64       455\n","        PERS       0.76      0.70      0.73       905\n","\n","   micro avg       0.71      0.76      0.73      2278\n","   macro avg       0.68      0.73      0.70      2278\n","weighted avg       0.72      0.76      0.74      2278\n","\n","------------------------------------------------------------\n","Epoch 3 - Loss: 0.0273\n","Validation:\n","F1: 0.7245646196150322\n","              precision    recall  f1-score   support\n","\n","         LOC       0.83      0.87      0.85       675\n","        MISC       0.59      0.56      0.57       243\n","         ORG       0.61      0.57      0.59       455\n","        PERS       0.83      0.66      0.74       905\n","\n","   micro avg       0.76      0.69      0.72      2278\n","   macro avg       0.71      0.67      0.69      2278\n","weighted avg       0.76      0.69      0.72      2278\n","\n","------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["def ner_predict(tokens):\n","    # tokenize correctly\n","    encoded = tokenizer(\n","        tokens,\n","        is_split_into_words=True,\n","        return_tensors=\"pt\",\n","        padding=True,\n","        truncation=True\n","    ).to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(**encoded)\n","        preds = outputs.logits.argmax(-1)[0].cpu().numpy()\n","\n","    # get word ids from batch encoding\n","    word_ids = encoded.word_ids()\n","\n","    results = []\n","    last_word = None\n","\n","    for i, w in enumerate(word_ids):\n","        if w is None or w == last_word:\n","            continue\n","\n","        label = id2label[preds[i]]\n","        results.append((tokens[w], label))\n","        last_word = w\n","\n","    return results\n","\n","\n","# test\n","ner_predict([\"محمد\", \"يسكن\", \"في\", \"دمشق\", \".\", \"الآن\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J0QZpUGQvchy","executionInfo":{"status":"ok","timestamp":1763937880464,"user_tz":-180,"elapsed":16,"user":{"displayName":"Mohammed Kassas","userId":"11667506908589043184"}},"outputId":"a8bc19c9-cf19-43aa-8635-9b37f20cb79e"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('محمد', 'B-PERS'),\n"," ('يسكن', 'O'),\n"," ('في', 'O'),\n"," ('دمشق', 'B-LOC'),\n"," ('.', 'O'),\n"," ('الآن', 'O')]"]},"metadata":{},"execution_count":43}]}]}